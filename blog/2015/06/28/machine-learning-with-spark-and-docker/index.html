<!DOCTYPE html>
<!--[if lt IE 7]>      <html class='no-js lt-ie9 lt-ie8 lt-ie7'> <![endif]-->
<!--[if IE 7]>         <html class='no-js lt-ie9 lt-ie8'> <![endif]-->
<!--[if IE 8]>         <html class='no-js lt-ie9'> <![endif]-->
<!--[if gt IE 8]><!--> <html class='no-js' itemscope itemtype='http://schema.org/WebPage'> <!--<![endif]-->
<!-- Head -->
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width initial-scale=1" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <!-- Site Metadata -->
    <title>Machine Learning with Spark and Docker | Mark Feltner's Website</title>
    <meta name="author" content="Mark Feltner">
    <meta name="description" content="Machine learning has recently been gaining a lot more of my interest, and this weekend I decided I was going to try and get something going. I was able to build a Apache Spark cluster on Hadoop running in Docker container. I used gradle project that I forked. (eat your …">


    <link rel="canonical" href="https://mark.feltner.me">
<link rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/vendor/normalize.css">
<link rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/vendor/typeset.css">
<link rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/grid.css">
<link rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/main.css">
<link rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/pygments.css">
<link media="print" rel="stylesheet" type="text/css" href="https://mark.feltner.me/theme/css/print.css"><!-- RSS Feeds -->
<!-- So Firefox can bookmark->"abo this site" -->
<link href="https://mark.feltner.me/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Mark Feltner's Website Full Atom Feed" />
<link href="https://mark.feltner.me/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Mark Feltner's Website Full RSS Feed" />
<link href="https://mark.feltner.me/feeds/atom.xml" type="application/atom+xml" rel="alternate" title="Mark Feltner's Website Atom Feed" />
<link href="https://mark.feltner.me/feeds/rss.xml" type="application/rss+xml" rel="alternate" title="Mark Feltner's Website RSS Feed" />
<!-- Favicons -->
<link rel="shortcut icon" href="https://mark.feltner.me/theme/images/favicon.ico" type="image/x-icon">
<link rel="icon" href="https://mark.feltner.me/theme/images/favicon.ico" type="image/x-icon">
<!--
<link rel="shortcut icon" href="https://mark.feltner.me/images/apple-touch-icon.png">
<link rel="shortcut icon" href="https://mark.feltner.me/images/apple-touch-icon-72x72.png">
<link rel="shortcut icon" href="https://mark.feltner.me/images/apple-touch-icon-114x72.png">
-->
    <link rel="humans" type="text/plain" href="https://mark.feltner.me/humans.txt">
    <link rel="hackers" type="text/plain" href="https://mark.feltner.me/hackers.txt">
</head>
    <body>
        <!--[if lt IE 7]>
            <p class='browsehappy'>You are using an <strong>outdated</strong> browser. Please <a href='http://browsehappy.com/'>upgrade your browser</a> to improve your experience.</p>
        <![endif]-->

        <div class='feltnerm-container'>
            <div class='feltnerm-header'>
<!-- Site Header -->
<div class="feltnerm-header-title">
    <header class="feltnerm-site-header" role="banner">
        <h1><a href="https://mark.feltner.me/">Mark Feltner's Website</a></h1>
    </header>
</div><div class='feltnerm-header-nav'>
    <div class='feltnerm-main-nav'>
        <nav aria-label="Main">
            <ul class="inline-list">
                <li><a href="/">home</a> · </li>
                <li><a href="/blog/">blog</a> · </li>
                <li><a href="/projects">projects</a> · </li>
                <li><a href="/portfolio">portfolio</a></li>
            </ul>
        </nav>
    </div>
</div>
            </div>

            <div class='feltnerm-content'>
<div class='feltnerm-article'>
    <article itemscope itemtype='http://schema.org/BlogPosting'>
        <header class='feltnerm-article-header'>
            <h1 itemprop='name'><a href='#' itemprop='url'>Machine Learning with Spark and Docker</a></h1>
        </header>
        <div class='feltnerm-article-meta'>
            <span class='feltnerm-article-meta-date'>
                Written on <time itemprop='datePublished' datetime='2015-06-28T00:00:00-05:00' content='2015-06-28T00:00:00-05:00'>Sunday, June 28, 2015</time>
            </span>
        </div>
        <div class='feltnerm-article-content'>
            <main itemprop='articleBody' class='typeset'>
                <p>Machine learning has recently been gaining a lot more of my interest, and this
weekend I decided I was going to try and get <em>something</em> going. I was able to build a <a href="https://spark.apache.org/">Apache Spark</a> cluster on
<a href="http://hadoop.apache.org/">Hadoop</a> running in <a href="https://www.docker.com/">Docker container</a>.
I used <a href="">gradle</a>
<a href="https://github.com/granthenke/spark-demo">project</a> that <a href="https://github.com/feltnerm/spark-demo">I forked</a>.
(eat your heart out crawlers!)</p>
<p>Here are my notes so I don&rsquo;t forget, and so you can maybe learn a thing or
two.</p>
<p>Apache Spark is a cluster-computation engine that can do machine-learning (and much more!).
We&rsquo;ll use this to compose ML algorithms using well-tested code, rather than trying to hand-code
complicated ML algorithms ourselves (although that does sound like a good
learning exercise, and there will be a bit of DIY ML involved later).</p>
<p>Spark is made to run on a Hadoop. As I understand it, Spark queries are
sent to Hadoop, and then Hadoop will do the job of decomposing the Spark
job/query into a series of steps that can be distributed over a number of machines and
safely combined when calculations are done. One of Spark&rsquo;s greatest strengths
is that is is able to assemble Map/Reduce jobs <em>in-memory</em> which greatly
increases the speed of our cluster.</p>
<p>This means the compute for our ML algorithms can potentially scale to
thousands of nodes. There may come a day when you&rsquo;re processing a massive
amount of data with a very intense algorithm, but &ndash; fortunately &ndash; today is
not that day. We&rsquo;ll keep it simple for now, but it&rsquo;s good to know what our
limitations and possibilities  are.</p>
<p>Docker is an operating-system virtualizer. Virtual machines virtualize hardware.
Docker virtualizes software. We will use docker to quickly run Hadoop
locally so we can send ML queries for it to process.</p>
<p>This is a great way to get started with new technology if you&rsquo;re at all like
me and need to get your hands dirty with new tools and tech in order to better
grasp them.</p>
<h2>Build our Workspace</h2>
<p><a href="https://github.com/feltnerm/spark-example">feltnerm/spark-example</a> is a fork of
<a href="https://github.com/granthenke/spark-demo">granthenke/spark-example</a>, a project that uses
gradle (the JVM build tool I am most familiar with)
I simply have updated a few things here and there including some dependencies.
This will help us to do some of the boring stuff including generating a fat JAR &ndash; a JAR containing all of our project
dependencies &ndash; which we can ship up to a Hadoop cluster to evaluate.</p>
<p>If you want to get started then clone that sucker:</p>
<div class="highlight"><pre><span></span><code>git clone https://github.com/feltnerm/spark-example
<span class="nb">cd</span> spark-example
gradle build

<span class="c1"># feel free to run one of the following to generate a project for a specific IDE</span>
gradle eclipse
<span class="c1"># or</span>
gradle idea
</code></pre></div>
<h2>Run a Spark-compatible Hadoop-cluster locally</h2>
<p>Now that we have something to run, we need something to run it against.</p>
<p>Lately, I&rsquo;ve been diggin&rsquo; docker for quickly spinning up non-trivial
applications. Looking at Hadoop&rsquo;s docs, it certainly looks like a
relatively non-trivial setup. By that, I mean I would probably get distracted
and move on before I finished.</p>
<p>Fortunately, the <a href="https://github.com/sequenceiq/docker-spark">docker-spark</a>
project proved to be the perfect way to get Hadoop running locally so I could
run Spark queries against it.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># pull down spark docker image</span>
docker pull sequenceiq/spark:1.4.0
</code></pre></div>
<h2>Build the Spark Query</h2>
<p>The following is an example Spark query, and the computation that we hope the
eventually run locally.</p>
<p>The following code will be, more or less, what our Hadoop cluster will run.
This code is ripped right from <a href="">@granthenke&rsquo;s spark-example</a></p>
<p>The explanation of how π is calculated from the <a href="http://spark.apache.org/examples.html">Spark examples</a>:</p>
<blockquote>
<p>Spark can also be used for compute-intensive tasks. This code estimates π by &ldquo;throwing darts&rdquo; at a circle. We pick random points in the unit square ((0, 0) to (1,1)) and see how many fall in the unit circle. The fraction should be π / 4, so we use this to get our estimate.</p>
</blockquote>
<div class="highlight"><pre><span></span><code><span class="k">package</span> <span class="nn">com</span><span class="p">.</span><span class="nn">feltnerm</span><span class="p">.</span><span class="n">sparkexample</span>

<span class="k">import</span> <span class="nn">scala</span><span class="p">.</span><span class="nn">math</span><span class="p">.</span><span class="n">random</span>

<span class="k">import</span> <span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span> <span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nc">SparkContext</span><span class="p">.</span><span class="n">_</span>

<span class="cm">/** Computes an approximation to pi */</span>
<span class="k">object</span> <span class="nc">SparkPi</span> <span class="p">{</span>
  <span class="k">def</span> <span class="nf">main</span><span class="p">(</span><span class="n">args</span><span class="p">:</span> <span class="nc">Array</span><span class="p">[</span><span class="nc">String</span><span class="p">])</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">length</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
      <span class="nc">System</span><span class="p">.</span><span class="n">err</span><span class="p">.</span><span class="n">println</span><span class="p">(</span><span class="s">&quot;Usage: SparkPi &lt;master&gt; [&lt;slices&gt;]&quot;</span><span class="p">)</span>
      <span class="nc">System</span><span class="p">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="p">}</span>

    <span class="c1">// Process Args</span>
    <span class="kd">val</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SparkConf</span><span class="p">()</span>
      <span class="p">.</span><span class="n">setMaster</span><span class="p">(</span><span class="n">args</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
      <span class="p">.</span><span class="n">setAppName</span><span class="p">(</span><span class="bp">this</span><span class="p">.</span><span class="n">getClass</span><span class="p">.</span><span class="n">getCanonicalName</span><span class="p">)</span>
      <span class="p">.</span><span class="n">setJars</span><span class="p">(</span><span class="nc">Seq</span><span class="p">(</span><span class="nc">SparkContext</span><span class="p">.</span><span class="n">jarOfClass</span><span class="p">(</span><span class="bp">this</span><span class="p">.</span><span class="n">getClass</span><span class="p">).</span><span class="n">get</span><span class="p">))</span>

    <span class="kd">val</span> <span class="n">spark</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">SparkContext</span><span class="p">(</span><span class="n">conf</span><span class="p">)</span>
    <span class="kd">val</span> <span class="n">slices</span> <span class="o">=</span> <span class="k">if</span> <span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">length</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="n">args</span><span class="p">(</span><span class="mi">1</span><span class="p">).</span><span class="n">toInt</span> <span class="k">else</span> <span class="mi">2</span>
    <span class="kd">val</span> <span class="n">n</span> <span class="o">=</span> <span class="mi">100000</span> <span class="o">*</span> <span class="n">slices</span>

    <span class="c1">// Run spark job</span>
    <span class="kd">val</span> <span class="n">count</span> <span class="o">=</span> <span class="n">spark</span><span class="p">.</span><span class="n">parallelize</span><span class="p">(</span><span class="mi">1</span> <span class="n">to</span> <span class="n">n</span><span class="p">,</span> <span class="n">slices</span><span class="p">).</span><span class="n">map</span> <span class="p">{</span> <span class="n">i</span> <span class="o">=&gt;</span>
      <span class="kd">val</span> <span class="n">x</span> <span class="o">=</span> <span class="n">random</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
      <span class="kd">val</span> <span class="n">y</span> <span class="o">=</span> <span class="n">random</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">-</span> <span class="mi">1</span>
      <span class="k">if</span> <span class="p">(</span><span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">0</span>
    <span class="p">}.</span><span class="n">reduce</span><span class="p">(</span><span class="n">_</span> <span class="o">+</span> <span class="n">_</span><span class="p">)</span>

    <span class="c1">// Output &amp; Close</span>
    <span class="n">println</span><span class="p">(</span><span class="s">&quot;Pi is roughly &quot;</span> <span class="o">+</span> <span class="mf">4.0</span> <span class="o">*</span> <span class="n">count</span> <span class="o">/</span> <span class="n">n</span><span class="p">)</span>
    <span class="n">spark</span><span class="p">.</span><span class="n">stop</span><span class="p">()</span>
  <span class="p">}</span>
<span class="p">}</span>
</code></pre></div>
<p>We&rsquo;re going to run the above code against a Spark-able Hadoop cluster, but
first we need to build a fat JAR &ndash; a JAR with <em>all</em> of our sources. We can
use <code>gradle</code> for this!</p>
<div class="highlight"><pre><span></span><code><span class="c1"># build hadoop fat jar</span>
% ./gradlew build
% ls build/libs/
spark-example-1.0-hadoop.jar  spark-example-1.0-javadoc.jar spark-example-1.0-sources.jar spark-example-1.0.jar
</code></pre></div>
<p>Once we have our JAR ready, we run a new Spark container, and
run the Spark fat-JAR that we just created via a shared filesystem mount.</p>
<div class="highlight"><pre><span></span><code><span class="c1"># run spark docker image, with the local build directory (`./build/libs/`) mounted under libs</span>
<span class="c1"># submit job to spark (example of SparkPi w/ arguments)</span>
<span class="c1"># note this is running on the spark cluster</span>
docker run --name spark --rm -it -p <span class="m">8088</span>:8088 -p <span class="m">8042</span>:8042 -v <span class="s2">&quot;</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">/build/libs/:/libs/&quot;</span> sequenceiq/spark:1.4.0 bash
</code></pre></div>
<p>Let&rsquo;s go over this&hellip;</p>
<p>We&rsquo;re interactively (<code>--it</code>) running (<code>run</code>) a Docker container named &lsquo;spark&rsquo;
(<code>--name spark</code>) based off the &lsquo;1.4.0&rsquo; tag of sequenceiq&rsquo;s spark image
(<code>sequenceiq/spark:1.4.0</code>) which we want to remove any trace of when we exit (<code>--rm</code>),
mapping ports 8088 and 8042 from the container to the host
(<code>-p 8088:8088 -p 8042:8042</code>) so we can remotely access Hadoop if needed,
and mounting the local directory containing our build artifacts to the container
(<code>$(pwd)/builds/libs/:/libs/</code>). Once the container starts we run <code>bash</code> (which sets up <code>$SCALA_HOME</code> and <code>$JAVA_HOME</code> for us),
and from here we can start our job..</p>
<p>The last step is to actually submit our job via <code>spark-submit</code>:</p>
<div class="highlight"><pre><span></span><code>spark-submit <span class="se">\</span>
--class com.feltnerm.sparkexample.SparkPi <span class="se">\</span>
--master yarn-client <span class="se">\</span>
--driver-memory 1g <span class="se">\</span>
--executor-memory <span class="m">1</span> <span class="se">\</span>
--executor-cores <span class="m">1</span> <span class="se">\</span>
/libs/sparkexample-1.0-hadoop.jar local<span class="o">[</span><span class="m">2</span><span class="o">]</span> <span class="m">100</span>
</code></pre></div>
<p>The above command is submitting the <code>/libs/sparkexample-1.0-hadoop.jar</code> to
Spark. The reason we are setting <code>--master yarn-client</code> is because
this is a single node cluster, and we only want the master node the run the
job.</p>
<p>Next, I&rsquo;ll post some actual machine learning algorithms and Spark code.</p>
            </section>
        </div>
    </article>
</div>
            </div>

            <hr></hr>

            <div class='feltnerm-footer'>
<!-- Site Footer -->
<div class='feltnerm-site-footer'>
    <footer>
        <div class="feltnerm-footer-social">
            <ul class="inline-list">
                <li><a href="https://github.com/feltnerm">github</a> · </li>
                <li><a href="https://twitter.com/feltnermj">twitter</a> · </li>
                <li><a href="http://www.last.fm/user/plugitin">last.fm</a> · </li>
                <li><a href="mailto:mark+blog@feltner.me">email</a></li>
            </ul>
        </div>
        <div class="feltnerm-footer-meta">
            <ul class="inline-list">
                <li><a href="/feeds/all.rss.xml">rss</a> · </li>
                <li><a href="/feeds/all.atom.xml">atom</a> · </li>
                <li><a href="/style-guide">style</a> · </li>
                <li><a href="/credits">credits</a></li>
            </ul>
        </div>
        <div class="feltnerm-footer-copyright">
            <p>© 2022, Mark Feltner
            <p>This <span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" rel="dct:type">work</span> is licensed under a
                <br><a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.</p>
        </div>
    </footer>
</div>            </div>

<!-- Site Javascripts --><!-- Analytics -->
<script>
    var _gaq=[['_setAccount',''],['_trackPageview']];
    (function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
    g.src='//www.google-analytics.com/ga.js';
    s.parentNode.insertBefore(g,s)}(document,'script'));
</script>
        </div>

    </body>
</html>